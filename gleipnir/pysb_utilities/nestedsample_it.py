import sys
import importlib
import os.path

def is_numbers(inputString):
    return all(char.isdigit() for char in inputString)

def parse_directive(directive, priors, no_sample, Keq_sample):
    words = directive.split()
    if words[1] == 'prior':
        if is_numbers(words[2]):
            par_idx = int(words[2])
            par = model.parameters[par_idx].name
        else:
            par = words[2]
        priors[par] = words[3]
    elif words[1] == 'no-sample':
        if is_numbers(words[2]):
            par_idx = int(words[2])
            par = model.parameters[par_idx].name
        else:
            par = words[2]
        no_sample.append(par)
    elif words[1] == 'sample_Keq':
        if is_numbers(words[2]):
            par_idx = int(words[2])
            par_f = model.parameters[par_idx].name
        if is_numbers(words[3]):
            par_idx = int(words[3])
            par_r = model.parameters[par_idx].name
        if is_numbers(words[4]):
            par_idx = int(words[4])
            par_rep = model.parameters[par_idx].name
        no_sample.append(par_rep)
        Keq_sample.append((par_f, par_r, par_rep))
    return

def prune_no_samples(parameters, no_sample):
    pruned_pars = [parameter for parameter in parameters if parameter[0].name not in no_sample]

    return pruned_pars

def update_with_Keq_samples(parameters, Keq_sample):
    k_reps = [sample[2] for sample in Keq_sample]
    pruned_pars = [parameter for parameter in parameters if parameter[0].name not in k_reps]
    return pruned_pars

def write_norm_param(p_name, p_val):
    line = "sp_{} = SampledParameter(\'{}\', norm(loc=np.log10({}), scale=2.0))\n".format(p_name, p_name, p_val)
    return line

def write_uniform_param(p_name, p_val):
    line = "sp_{} = SampledParameter(\'{}\', uniform(loc=np.log10({})-1.0, scale=2.0))\n".format(p_name, p_name, p_val)
    return line

if __name__ == '__main__':
    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument('model_file', metavar='model_file', type=str, help='The model.py file that you want run NS on.')
    parser.add_argument('output_path', metavar='output_path', type=str, help='The file location where you want to output the NS run script.')
    args = parser.parse_args()
    # get the input script from command line imputs
    model_file = os.path.abspath(args.model_file)
    # get the location to dump the output
    output_path = os.path.abspath(args.output_path)

    print("Using model from file: {}".format(model_file))
    base=os.path.basename(model_file)
    model_module_name = os.path.splitext(base)[0]
    print("With name: {}".format(model_module_name))
    default_prior_shape = 'norm'
    print("The default prior shape is: {}".format(default_prior_shape))
    #print(model_file)

    #print(model_module_name)
    model_module = importlib.import_module(model_module_name)
    model = getattr(model_module, 'model')
    #print(model)
    priors = dict()
    no_sample = list()
    Keq_sample = list()
    #Read the file and parse any #NESTEDSAMPLE_IT directives
    print("Parsing the model for any #NESTEDSAMPLE_IT directives...")
    with open(model_file, 'r') as file_obj:
        for line in file_obj:
            words = line.split()
            if len(words) > 1:
                if words[0] == '#NESTEDSAMPLE_IT':
                    parse_directive(line, priors, no_sample)

    #now we need to extract a list of kinetic parameters
    parameters = list()
    print("Inspecting the model and pulling out kinetic parameters...")
    for rule in model.rules:
        print(rule.rate_forward, rule.rate_reverse)
        #print(rule_keys)
        if rule.rate_forward:
            param = rule.rate_forward
            #print(param)
            parameters.append([param,'f'])
        if rule.rate_reverse:
            param = rule.rate_reverse
            #print(param)
            parameters.append([param, 'r'])
    #print(no_sample)
    parameters = prune_no_samples(parameters, no_sample)
    parameters = update_with_Keq_samples(parameters, Keq_sample)
    #print(parameters)
    print("Found the following kinetic parameters:")
    print("{}".format(parameters))
    #default the priors to norm - i.e. normal distributions
    for parameter in parameters:
        name = parameter[0].name
        if name not in priors.keys():
            priors[name] = default_prior_shape

    # Obtain mask of sampled parameters to run simulation in the likelihood function
    parameters_idxs = [model.parameters.index(parameter[0]) for parameter in parameters]
    rates_mask = [i in parameters_idxs for i in range(len(model.parameters))]
    param_values = [p.value for p in model.parameters]

    out_file = open("run_NS_"+base, 'w')

    print("Writing to Gleipnir NS run script: run_NS_{}".format(base))
    out_file.write("\'\'\'\nGenerated by nestedsample_it\n")
    out_file.write("Gleipnir NS run script for {} \n".format(base))
    out_file.write("\'\'\'")
    out_file.write("\n")
    out_file.write("from pysb.simulator import ScipyOdeSimulator\n")
    out_file.write("import numpy as np\n")
    out_file.write("from scipy.stats import norm,uniform\n")
    out_file.write("from gleipnir.nested_sampling import NestedSampling\n")
    out_file.write("from gleipnir.samplers import MetropolisComponentWiseHardNSRejection\n")
    out_file.write("from gleipnir.sampled_parameter import SampledParameter\n")
    out_file.write("from gleipnir.stopping_criterion import NumberOfIterations\n")

    #out_file.write("import inspect\n")
    #out_file.write("import os.path\n")
    out_file.write("from "+model_module_name+" import model\n")
    out_file.write("\n")

    out_file.write("# Initialize PySB solver object for running simulations.\n")
    out_file.write("# Simulation timespan should match experimental data.\n")
    out_file.write("tspan = np.linspace(0,10, num=100)\n")
    out_file.write("solver = ScipyOdeSimulator(model, tspan=tspan)\n")
    out_file.write("parameters_idxs = " + str(parameters_idxs)+"\n")
    out_file.write("rates_mask = " + str(rates_mask)+"\n" )
    out_file.write("param_values = np.array([p.value for p in model.parameters])\n" )
    out_file.write("\n")
    out_file.write("# USER must add commands to import/load any experimental\n")
    out_file.write("# data for use in the likelihood function!\n")
    out_file.write("experiments_avg = np.load()\n")
    out_file.write("experiments_sd = np.load()\n")
    out_file.write("like_data = norm(loc=experiments_avg, scale=experiments_sd)\n")
    out_file.write("# USER must appropriately update loglikelihood function!\n")
    out_file.write("def loglikelihood(position):\n")
    out_file.write("    Y=np.copy(position)\n")
    out_file.write("    param_values[rates_mask] = 10 ** Y\n")
    out_file.write("    sim = solver.run(param_values=param_values).all\n")
    out_file.write("    logp_data = np.sum(like_data.logpdf(sim['observable']))\n")
    out_file.write("    if np.isnan(logp_data):\n")
    out_file.write("        logp_data = -np.inf\n")
    out_file.write("    return logp_data\n")
    out_file.write("\n")
    #write the sampled params lines
    out_file.write("sampled_parameters = list()\n")
    for parameter in parameters:
        name = parameter[0].name
        value = parameter[0].value
        prior_shape = priors[name]
        print("Will sample parameter {} with {} prior around {}".format(name, prior_shape, value))
        if prior_shape == 'uniform':
            line = write_uniform_param(name, value)
            ps_name = line.split()[0]
            out_file.write(line)
            out_file.write("sampled_parameters.append({})\n".format(ps_name))
        else:
            line = write_norm_param(name, value)
            ps_name = line.split()[0]
            out_file.write(line)
            out_file.write("sampled_parameters.append({})\n".format(ps_name))

    out_file.write("# Setup the Nested Sampling run\n")
    out_file.write("n_params = len(sampled_parameters\n")
    out_file.write("population_size = 10*n_params\n")
    out_file.write("# Setup the sampler to use when updating points during the NS run --\n")
    out_file.write("# Here we are using an implementation of the Metropolis Monte Carlo algorithm\n")
    out_file.write("# with component-wise trial moves and augmented acceptance criteria that adds a\n")
    out_file.write("# hard rejection constraint for the NS likelihood boundary.\n")
    out_file.write("sampler = MetropolisComponentWiseHardNSRejection(iterations=500, burn_in=100)\n")
    out_file.write("# Setup the stopping criterion for the NS run -- We'll use a fixed number of\n")
    out_file.write("# iterations: 10*population_size\n")
    out_file.write("stopping_criterion = NumberOfIterations(10*population_size)\n")
    out_file.write("# Construct the Nested Sampler\n")
    out_file.write("NS = NestedSampling(sampled_parameters=sampled_parameters,\n")
    out_file.write("                    loglikelihood=loglikelihood, sampler=sampler,\n")
    out_file.write("                    population_size=population_size,\n")
    out_file.write("                    stopping_criterion=stopping_criterion)\n")
    out_file.write("# run it\n")
    out_file.write("NS.run()\n")
    out_file.write("# Retrieve the evidence\n")
    out_file.write("evidence = NS.evidence()\n")
    out_file.write("print(\"evidence: \",evidence)\n")
    out_file.write("print(\"log_evidence: \", np.log(evidence))\n")


    out_file.close()
    print("nestedsample_it is complete!")
    print("END OF LINE.")
